{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Police Deployment Analysis\n",
    "\n",
    "While we can go into all the math and metrics around the performance of a model, ultimately its primary use--as a deployment tool--is the most important test: can the CrimesScape model actually give us a meaningful and important improvement over existing methods? \n",
    "\n",
    "This notebook runs through a deployment analysis that gives context to the ways in which deployment using CivicScape can have substantial impact. Every police department deploys officers in a different way that is right for their community; in this document, we make some clarifying assumptions that allow us to quantify the improvements that could be attained through the use of CivicScape. We will go through those below. \n",
    "\n",
    "### Comparison Point: COMPSTAT\n",
    "\n",
    "If you have already been through the Model Data Practices document, you're familiar with COMPSTAT: we're using the same system as a baseline here.\n",
    "\n",
    "While there are a few other machine-learning driven systems that also do crime risk assessment, much like CivicScape, most communities in the US still rely on a system that is broadly refered to as COMPSTAT: a data-driven policing deployment approach that encompasses a wide variety of different techniques and methodologies. Often, COMPSTAT uses historical crime count averages to anticipate high-crime areas for a given beat assignment. \n",
    "\n",
    "This seems like a pretty good comparison point for us. Since many police departments use something similar, it will help us understand how the additional features we've added--plus the algorithms used--can improve upon existing systems. So, we use *three year historical averages* for tract/day combinations and use these to establish a baseline for comparison against the same test data that we compared our model to above. You could also try configuring your own set of risk assessments and using this notebook to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import notebook_support\n",
    "import numpy as np\n",
    "\n",
    "# Example City Coordinates for Folium maps; extend for new cities\n",
    "coords = {\"CHICAGO\": (41.8781, -87.6298), \"OAKLAND\": (37.8044, 122.2711), \"NEW YORK CITY\": (40.7831, 73.9712), \n",
    " \"NEW ORLEANS\": (29.9511, 90.0715)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping the Data\n",
    "\n",
    "We need a few files to run this analysis: \n",
    "\n",
    "1. *CivicScape Risk Scores* - a CSV file\n",
    "2. *Historical Crime Data* (three-year historical) - a CSV file\n",
    "3. *Census Tracts Geojson* - a geographic file for census tracts\n",
    "4. *Police Beats Geojson* - the regions to which police are deployed; this may be districts, potentially, or, if there aren't available geographic information, just feed in the same census tract file. \n",
    "\n",
    "**To Begin**: enter in the file paths for the data you wish you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "census_tracts = 'geojsons/CensusTracts2000.geojson'\n",
    "police_beats = 'geojsons/PoliceBeats.geojson'\n",
    "riskscores_path = \"../data/risk_assessments.csv\"\n",
    "hist_path = \"../data/historical_grouped_3_year.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run the following two modules to load and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data files were loaded! You're ready to start!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "riskscores = pd.read_csv(riskscores_path)\n",
    "beats = pd.read_json(police_beats)\n",
    "tracts = pd.read_json(census_tracts)\n",
    "historical = pd.read_csv(hist_path)\n",
    "notebook_support.data_check(riskscores, historical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data prep done!\n",
      "This file contains risk_assessments for the test date range 2014-10-24 00:00:00 through 2015-05-28 00:00:00.\n",
      "\n",
      "Looks like your historical dataset doesn't have days, so we'll look at months instead.\n",
      "\n",
      "The period from 2014-10-01 00:00:00 to 2014-10-24 00:00:00 will be left off the dataset because data are missing.\n",
      "\n",
      "The period from 2015-05-28 00:00:00 to 2015-09-01 00:00:00 will be left off the dataset because data are missing.\n",
      "\n",
      "The final overlapping period for analysis is: 2014-10-24 00:00:00 through 2015-05-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "risk, hist = notebook_support.data_prep(riskscores, historical)\n",
    "risk_keep, risk, hist = notebook_support.historical_prep(risk, hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Community and Timeframe\n",
    "\n",
    "Now, select the community that you'd like to run the analysis for. We have a lot of pre-set jurisdictions based on where CivicScape already has data, listed below. If you'd like to add another city, please use the first code module above to insert the lat/long location. As long as your other data are in the correct format, this notebook should still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Jurisdictions for Analysis: ['NEW YORK CITY', 'NEW ORLEANS', 'OAKLAND', 'CHICAGO']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAvailable Jurisdictions for Analysis: {}\\n\".format(coords.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city = 'chicago'\n",
    "map_cs_risk = folium.Map(location=coords[city.upper()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, please select a timeframe. Keep in mind that if you want to do a deployment comparison, you should restrict the data to a specific timeframe and shift. We currently have this set to Fridays 12:00-8:00am for the period 11/01/2014 through 02/01/2015, but you should edit it for your data and interest. Ideally, it'd be best to look at a single shift time (e.g. 12-8am or whatever makes sense for your city)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You've restricted the risk score data for the following dates:\n",
      "    2014-11-01 00:00:00 through 2014-11-08 00:00:00\n"
     ]
    }
   ],
   "source": [
    "hours = () # Enter the hour range to include on a 24-hour clock, e.g. (3, 15) returns 3AM-3PM\n",
    "days = [] # Enter each day to include as a letter i.e. ['M', 'T', 'W', 'R', 'F', 'Sa', 'Su']\n",
    "date_range = ('2014-11-01', '2014-11-08') # Enter the dates as YYYY-MM-DD, e.g. ('2014-10-24', '2015-05-28')\n",
    "riskscores, historical = notebook_support.constrict_times(risk, historical=hist, hours=hours, days=days, date_range=date_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model makes a lot of assumptions in order to be able to quantify potential impact. \n",
    "\n",
    "### Assumption Set 1: How Officers are Deployed\n",
    "\n",
    "We assume a two-tiered process for deployment. First, we assume that a subset of the officers available for a given shift are placed on regular patrol; that is, they are deployed to a standard patrol of a particular beat. We then assume that the remaining officers are available for areas which are high-risk: we call these 'floating' patrol officers. We need you to tell us \n",
    "\n",
    "1. How many officers are available.\n",
    "2. What percent of those officers are for regular patrol, as a decimal.\n",
    "3. How many floating officers to assign to a beat when it's considered risky.\n",
    "4. The shift length (though, it's recommended you just restrict your time period to a single shift above). If your time period you selected doesn't cover a full shift, you'll get an error below. \n",
    "\n",
    "Enter these values below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patrol_officers_for_shift = 2500 # How many officers available\n",
    "percent_regular_patrol = .60 # What percent are regular patrol\n",
    "percent_floating_patrol = 1-percent_regular_patrol # We assume other officers are available for floating patrol\n",
    "additional_when_highrisk_beat = 3 # How many officers to assign to high risk beats\n",
    "shift_length = 8 # How long the shift is in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption Set 2: Probabilities\n",
    "\n",
    "Like with the Model Data Practices notebook, we have to set thresholds for when to deploy officers. It may be a good idea to use the optimal threshold from that notebook for the CivicScape threshold, since that should reduce False Positives and False Negatives, but you can play around with it. We have set those values to some default values below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold_for_CivicScape_assignment = .46\n",
    "threshold_for_COMPSTAT_assignment = .66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also not guaranteed that a patrol is able to stop a crime from happening, even with additional officers. For that reason, we add some uncertainty; we don't assume that additional police *will* stop a crime in every instance, only that there is some probability for doing so. Below, we have set the likelihood a CivicScape floating patrol stops a crime and the likelihood a COMPSTAT floating patrol stops a crime when the risk score is high.\n",
    "\n",
    "We kept these the same for CivicScape and COMPSTAT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CS_likelihood_patrol_stops_crime = .60 # What is the likelihood a CivicScape floating patrol stops a crime?\n",
    "COMP_likelihood_patrol_stops_crime = .60 # What is the likelihood a COMPSTAT floating patrol stops a crime?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we do a couple of calculations and check to make sure that the time range isn't too short for the shift. If you get an error, it's because the hour period you selected above is too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "officers_per_tract = percent_regular_patrol*patrol_officers_for_shift / len(tracts)\n",
    "additional_when_highrisk_tract = additional_when_highrisk_beat / officers_per_tract\n",
    "\n",
    "if hours != () and hours[1] - hours[0] < shift_length: \n",
    "    print(\"\\nWARNING: Time range too short for shift length.\\n\")\n",
    "    raise ValueError\n",
    "    \n",
    "assumptions = notebook_support.build_assumptions_dict(threshold_for_CivicScape_assignment, threshold_for_COMPSTAT_assignment, \n",
    "                                     CS_likelihood_patrol_stops_crime, threshold_for_COMPSTAT_assignment, \n",
    "                                     COMP_likelihood_patrol_stops_crime, additional_when_highrisk_tract, \n",
    "                                     percent_floating_patrol, patrol_officers_for_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We estimate the following for COMPSTAT and CivicScape:\n",
    "\n",
    "1. **Tracts at risk**: The number of tracts which are 'high risk' based on the threshold set above. \n",
    "2. **Additional Officers Necessary**: How many floating officers are needed to deploy to each beat containing a high-risk tract.\n",
    "3. **Overtime Officers**: If there aren't enough floating officers available, how many overtime officers would need to come outside of their scheduled shift.\n",
    "4. **Extra officers**: Officers that are availabile, but not needed for floating patrols.\n",
    "4. **Estimated Crimes Stopped**: Given the probability that a floating patrol would stop a crime if sent to a high-risk beat, how many crimes are estimated to have been either deterred or halted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist_merged, risk_merged, ranks = notebook_support.get_paper_comparisons(risk_keep, riskscores, historical, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n\\nCrimeScape tracts at risk: ', 268)\n",
      "('    Additional officers necessary: ', 268.0)\n",
      "('    Overtime officers: ', 0)\n",
      "('    Extra officers: ', 732.0)\n",
      "    Estimated crimes stopped: 37.00\n",
      "('\\nCOMPSTAT tracts at risk: ', 268)\n",
      "('    Additional officers necessary: ', 268.0)\n",
      "('    Overtime officers: ', 0)\n",
      "('    Extra officers: ', 732.0)\n",
      "    Estimated crimes stopped: 31.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_risk, hist_merged = notebook_support.police_deployment_analysis(hist_merged, risk_merged, assumptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the CivicScape risk map for this time period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_civ = average_risk\n",
    "map_civ['census_tra'] = map_civ['census_tra'].astype(str)\n",
    "for i in range(len(map_civ)):\n",
    "    while len(map_civ.loc[i, 'census_tra']) != 6: \n",
    "        map_civ.loc[i, 'census_tra'] = '0' + map_civ.loc[i, 'census_tra']\n",
    "\n",
    "map_cs_risk.choropleth(geo_path=census_tracts, data=map_civ,\n",
    "             columns=['census_tra', 'risk_assessment'],\n",
    "             key_on='feature.properties.census_tra',\n",
    "             fill_color='YlOrRd', fill_opacity=0.7, line_opacity=0.2,\n",
    "             legend_name='Risk Score',\n",
    "             reset=True)\n",
    "# folium.GeoJson(open(police_beats), name='geojson').add_to(map_cs_risk)\n",
    "map_cs_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the corresponding map for the COMPSTAT scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_hist = hist_merged\n",
    "map_hist['census_tra'] = map_hist['census_tra'].astype(str)\n",
    "for i in range(len(map_hist)):\n",
    "    while len(map_hist.loc[i, 'census_tra']) != 6: \n",
    "        map_hist.loc[i, 'census_tra'] = '0' + map_hist.loc[i, 'census_tra']\n",
    "map_comp_risk = folium.Map(location=coords[city.upper()])\n",
    "map_comp_risk.choropleth(geo_path=census_tracts, data=map_hist,\n",
    "             columns=['census_tra', 'risk_score'],\n",
    "             key_on='feature.properties.census_tra',\n",
    "             fill_color='YlOrRd', fill_opacity=0.7, line_opacity=0.2,\n",
    "             legend_name='Risk Score',\n",
    "             reset=True)\n",
    "map_comp_risk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
